\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

\begin{document}

<<setup, cache=FALSE,echo=FALSE>>=
library(ggplot2)
library(ggthemes)
@

\title{}

\author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID} % Add your name here
\and
\IEEEauthorblockN{Juan J. Merelo-Guerv\'os}
\IEEEauthorblockA{\textit{Dept. of Computer Architecture and Technology} \\
\textit{University of Granada}\\
Granada, Spain \\
jmerelo@ugr.es}

}
%\authorrunning{Merelo et al.}
%\titlerunning{Exploring concurrent and stateless EAs}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
\end{abstract}
\begin{IEEEkeywords}
  Concurrent algorithms, distributed computing, stateless algorithms,
algorithm implementation, performance evaluation.
\end{IEEEkeywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

\section{Motivation}
Machine learning has had a huge impact recently across many sectors such as the automobile, medical or defense industries. This progress comes along with more complex machine learning models where many parameters need to be adjusted to optimize the usefulness of the resulting trained model. Optimizing these parameters is not easy work and it is usually a time-consuming task as well as requires expertise to do it properly.

The traditional way of performing parameter optimization is Grid Search which is an exhaustive search through a manually specified subset of the parameters space of a learning algorithm ~\cite{wikipedia-Hyperparameter_optimization}. The model has to be trained with all the possible combinations for the values of the different parameters; this can take a lot of time for models where we want to test several parameters with many possible values each one. For example, the time complexity of Grid Search for a model with two parameters where $n$ values are tested for the first parameter and $m$ for the second one is $O(n \times m)$.

Another well-known approach is called Evolutionary Optimization which uses Evolutionary Algorithms for parameter optimization. Evolutionary algorithms (to be further known as an EA) are optimization algorithms that use mechanisms inspired by biological processes such as reproduction, mutation or selection. They apply these mechanisms over a population which consists of a set of candidate solutions (in this case a set of values for the parameters of the model we want to train) known as individuals. Each individual is evaluated with a fitness function that determines the quality of a solution ~\cite{wikipedia-Evolutionary_Algorithm}; for a machine learning model this fitness model can be the accuracy of its predictions.

Evolutionary algorithms are a successful approach to solve many difficult problems because they are easy to understand, simple to code and have a good performance ~\cite{Intro-to-EA}. But it can take a considerable amount of time to run an EA on a single machine depending on the complexity of the fitness function, the size of the population and how many generations we want to simulate.

Today we have an incredible amount of resources available for computation, most of them are wasted being partially idle all the time. What about using these potential resources to help science by running evolutionary algorithms in a distributed way?

This project aims to take advantage of this opportunity by providing a tool to deploy distributed evolutionary algorithms and enabling both tech-savvy and non-tech-savvy people to contribute to solving problems with their machines.

We cannot control how the users of the platform will behave in terms of how much time will they invest collaborating in our platform, therefore, we need our system to scale well with an ephemeral and heterogeneous environment where nodes can disappear without previous notice and can have an important performance difference between each other, or even being implemented in different languages. 

The overall objective of this project is to provide a tool for researchers and contributors to run Evolutionary Algorithms in a distributed way while minimizing the effort they need to make in order to do so. We can break it down in the following objectives:

\begin{itemize}
    \item Maximize engagement of the contributor user.
    
    \item Provide a fault-tolerant design capable of working with heterogeneous and ephemeral nodes.
    
    \item Achieve higher performance level than a non-distributed implementation.
\end{itemize}

Even though JavaScript performance has improved dramatically in recent years, its performance is still much lower than low-level languages since either compilation or interpretation are done at runtime. Therefore, tasks that require relatively high computational power have been executed server-side. In 2015 \cite{wasm-roadmap}, an alternative to JavaScript for intensive use cases began to take shape and in 2017, WebAssembly \cite{webassembly-announcement} was released as a web standard \cite{w3c-wasm}. 

WebAssembly, abbreviated as wasm, provides major gains in performance, by compiling low-level languages to a compact binary format that is executed by web-browsers with near-native performance \cite{wasm-concepts}. Furthermore, whereas compiling a large JavaScript script can take long, wasm files are already compiled and optimized out thus the time needed to start executing code is much smaller compared. 

Wasm does not attempt to replace JavaScript, instead, it aims to be an extra component that developers can integrate into their JavaScript application for intense tasks. So that, a communication layer between WebAssembly and JavaScript is provided in order to access JS functions from wasm and the other way around.

In \cite{wasm-compared}, a real-world experiment comparing WebAssembly to compiled and non-compiled JavaScript was carried out by running a \textit{GameBoy} emulator on different browsers and devices. The result was a superior performance of wasm in every scenario being up to 11.71 times faster than JavaScript in Firefox, and 1.45 times faster than compiled JavaScript in chrome. Moreover, in mobile browsers the difference is even bigger; being wasm 16.11 times faster than raw JS, and 2.07 times faster than compiled JS.






% The rest of the paper is organized as follows... 

\section{State of the art}

A pool storing chromosomes is shared between processors that do no know each others. The pool is divided into as many segments as processors. A processors can take any chromosome within the entire population, but can only overwrite a chromosome in its assigned segment to avoid race conditions.

Processors randomly reads as many chomosomes from the pool as they have within their segments. Then, after applying genetics operators, they replace the chromosomes on their segment with the resulting offsprings that have better fitness than the original. 

Since processors do not know each other and race conditions are under control, asynchronization and heterogeneity are almost intrinsic properties on this model. Moreover, new processors can easily join and leave asynchronously by dynamically resizing the segments each processor has.

As in Marter-Slave, the pool in this model is a single point of failure that limits the fault tolerance of the system. Replication of the pool can help to address this issue by backing up the state of the pool in case it goes down during the execution of the algorithm. 

Even though JavaScript performance has improved dramatically in recent years, its performance is still much lower than low-level languages since either compilation or interpretation are done at runtime. Therefore, tasks that require relatively high computational power have been executed server-side. In 2015 \cite{wasm-roadmap}, an alternative to JavaScript for intensive use cases began to take shape and in 2017, WebAssembly \cite{webassembly-announcement} was released as a web standard \cite{w3c-wasm}. 

% Not related to above. This will probably have to be rewritten and linked.

WebAssembly, abbreviated as wasm, provides major gains in performance, by compiling low-level languages to a compact binary format that is executed by web-browsers with near-native performance \cite{wasm-concepts}. Furthermore, whereas compiling a large JavaScript script can take long, wasm files are already compiled and optimized out thus the time needed to start executing code is much smaller compared. 

Wasm does not attempt to replace JavaScript, instead, it aims to be an extra component that developers can integrate into their JavaScript application for intense tasks. So that, a communication layer between WebAssembly and JavaScript is provided in order to access JS functions from wasm and the other way around.

In \cite{wasm-compared}, a real-world experiment comparing WebAssembly to compiled and non-compiled JavaScript was carried out by running a \textit{GameBoy} emulator on different browsers and devices. The result was a superior performance of wasm in every scenario being up to 11.71 times faster than JavaScript in Firefox, and 1.45 times faster than compiled JavaScript in chrome. Moreover, in mobile browsers the difference is even bigger; being wasm 16.11 times faster than raw JS, and 2.07 times faster than compiled JS.








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental setup and results}
\label{sec:res}


\section{Conclusions and discussion}
\label{sec:conclusions}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

This paper has been supported in part by projects DeepBio (TIN2017-85727-C4-2-P) and AMED (co-funded by European Regional Development Fund and the region Normandy).

\bibliographystyle{IEEEtran}
\bibliography{geneura,concurrent,bibliografia}

\end{document}
